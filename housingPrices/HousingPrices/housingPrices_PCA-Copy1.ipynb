{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (RandomForestRegressor, IsolationForest)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import (train_test_split, GridSearchCV, cross_val_score)\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (StandardScaler, RobustScaler, OneHotEncoder, FunctionTransformer, KBinsDiscretizer)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "import time\n",
    "import AveragedModels as av\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import ml_helper2 as mlh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KitchenQual', 'GarageCond', 'GarageQual', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'LotConfig', 'Utilities', 'LandSlope', 'LotShape', 'GarageType', 'BldgType', 'CentralAir', 'MSZoning', 'LandContour', 'PavedDrive']\n"
     ]
    }
   ],
   "source": [
    "# constants and helper methods\n",
    "\n",
    "CONDITIONS_DICT = {\"NA\": 0, \"NaN\": 0, \"nan\": 0, \"Po\": 2, \"Fa\": 3, \"TA\": 4, \"Gd\":6, \"Ex\": 10}\n",
    "\n",
    "# constants\n",
    "CATEGORY_LABELS = {\"KitchenQual\":       CONDITIONS_DICT,\n",
    "                    \"GarageCond\":       CONDITIONS_DICT,\n",
    "                    \"GarageQual\":       CONDITIONS_DICT,\n",
    "                    \"ExterQual\":        CONDITIONS_DICT,\n",
    "                    \"ExterCond\":        CONDITIONS_DICT,\n",
    "                    \"BsmtQual\":         CONDITIONS_DICT,\n",
    "                    \"BsmtCond\":         CONDITIONS_DICT,\n",
    "                    \"FireplaceQu\" :     CONDITIONS_DICT,\n",
    "                    \"HeatingQC\" :       CONDITIONS_DICT,\n",
    "                    \"LotConfig\":     {\"Inside\": 0, \"Corner\": 6, \"CulDSac\": 10, \"FR2\": 3, \"FR3\":4},\n",
    "                    \"Utilities\":     {\"ELO\": 0, \"NoSeWa\": 1, \"NoSewr\": 2, \"AllPub\": 3},\n",
    "                    \"LandSlope\":     {\"Gtl\": 10, \"Mod\": 4, \"Sev\": 1},\n",
    "                    \"LotShape\":     {\"Reg\": 10, \"IR1\": 5, \"IR2\": 3, \"IR3\": 1},\n",
    "                    \"GarageType\":     {\"NA\": 0, \"nan\": 0, \"Basment\": 4,  \"Detchd\": 1, \"CarPort\": 3, \"BuiltIn\": 5, \"Attchd\": 7, \"2Types\": 12},\n",
    "                    \"BldgType\":     {\"TwnhsI\": 1, \"Twnhs\": 2, \"TwnhsE\": 3, \"Duplex\": 5,  \"2fmCon\": 7, \"1Fam\": 12},\n",
    "                    \"CentralAir\":     {\"N\": 1, \"Y\": 10},\n",
    "                    \"Electrical\":     {\"Mix\": 1, \"FuseP\": 3, \"FuseF\": 5,  \"FuseA\": 7, \"SBrkr\": 12},\n",
    "                    \"MSZoning\":     {\"RL\": 100, \"RM\": 60, \"C (all)\": 20, \"FV\": 30, \"RH\": 30},\n",
    "                    \"LandContour\":     {\"Lvl\": 100, \"Low\": 15, \"Bnk\": 25, \"HLS\": 5},\n",
    "                    \"Fence\":     {\"NA\": 0, \"MnPrv\": 25, \"MnWw\": 15, \"GdWo\": 40, 'GdPrv': 100},\n",
    "                    \"Functional\":     {\"Typ\": 100, \"Min1\": 70, \"Min2\": 50, \"Mod\": 40, \"Maj1\": 25, \"Maj2\": 20, \"Min2\": 10, \"Sev\": 5, \"Sal\": 1},\n",
    "                    \"MiscFeature\":     {\"NA\": 0, \"Shed\": 30, \"Gar2\": 40, \"Othr\": 25, \"TenC\": 100},\n",
    "                    \"PavedDrive\":     {\"Y\": 100, \"P\": 30, \"N\": 0},\n",
    "                    }\n",
    "\n",
    "CAT_COLS_TO_IGNORE = [\"Functional\",\n",
    "                        \"MiscFeature\",\n",
    "                        \"Electrical\",\n",
    "                        \"Fence\",\n",
    "                        \"FireplaceQu\",\n",
    "                        \"HeatingQC\"           \n",
    "                    ]\n",
    "\n",
    "CAT_COLS = [ x for x in CATEGORY_LABELS.keys() if x not in CAT_COLS_TO_IGNORE]\n",
    "print(CAT_COLS)\n",
    "\n",
    "# plot correlations\n",
    "def plotCoorelations(df):\n",
    "    # remove non_numeric features  \n",
    "    corr = df.corr()\n",
    "    corr.style.background_gradient(cmap='coolwarm').set_precision(2)\n",
    "\n",
    "# define a method to use Isolation Forest for outlier detection\n",
    "def outlierRemoval_IsolationForest(X, y, outlierFraction = 0.02):\n",
    "    clf = IsolationForest( behaviour = 'new', contamination = outlierFraction)\n",
    "    preds = clf.fit_predict(X)\n",
    "    outliers = np.where(preds == -1)\n",
    "    return dropOutliers(X, y, outliers)\n",
    "\n",
    "def dropOutliers(X, y, outliers):\n",
    "    print(\"number of outliers = {0}\".format(len(outliers[0])))\n",
    "    # drop outliers\n",
    "    X_clean = np.delete(X, outliers[0], axis = 0)\n",
    "    y_clean = np.delete(y.values, outliers[0])\n",
    "    return X_clean, y_clean, outliers[0] \n",
    "\n",
    "# define a method to use Isolation Forest for outlier detection\n",
    "def outlierRemoval_ZScore(X, y, zValue = 3, bypass=False):\n",
    "    if bypass:\n",
    "        return X, y, []\n",
    "    z = np.abs(stats.zscore(X))\n",
    "    outliers = np.where(z > zValue)\n",
    "    return dropOutliers(X, y, outliers)\n",
    "\n",
    "def getTransformedColumnNames(ct):\n",
    "    for item in ct.named_transformers_:\n",
    "       pipeline = ct.named_transformers_[item]\n",
    "       for step in pipeline.named_steps:\n",
    "           t1 = pipeline.named_steps[step]\n",
    "           print(t1.get_feature_names())\n",
    "            \n",
    "  \n",
    "def displayScoresExp1p(scores):\n",
    "    print(\"Scores:\", np.expm1(scores))\n",
    "    print(\"Mean:\", np.expm1(scores.mean()))\n",
    "    print(\"standard deviation:\", np.expm1(scores.std()))\n",
    "    \n",
    "def displayScores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"standard deviation:\", scores.std())\n",
    "    \n",
    "def columnsWithMissingData(X, threshold = 0.9):\n",
    "    # check for null items\n",
    "    null_df = X.columns[X.isnull().any()]\n",
    "    null_count = X[null_df].isnull().sum()/len(X.index)\n",
    "    null_count_above_threshold = null_count.loc[null_count > threshold]\n",
    "    null_count_above_threshold\n",
    "    \n",
    "    #percentage of zero values for each numeric variable\n",
    "    zero_df = X.columns[(X == 0).any()]\n",
    "    zero_count = (X[zero_df] == 0).sum()/len(X.index)\n",
    "    zero_count_above_threshold = zero_count.loc[zero_count > threshold]\n",
    "    return pd.concat([null_count_above_threshold, zero_count_above_threshold])\n",
    "\n",
    "def crossValidateModel(model, X, y, name=\"<unknown>\", nthreads = -1):\n",
    "    start = time.time()\n",
    "    scores = cross_val_score(model, X, y, scoring = \"neg_mean_absolute_error\", n_jobs = nthreads, verbose = 10, cv = 5)\n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    print(\"model {0} cross_val_score took {1} seconds\".format(name, elapsed_time))\n",
    "    displayScores(-scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load housing data\n",
    "iowa_file_path = '../data/train.csv'\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = home_data[\"SalePrice\"]\n",
    "X = home_data.drop(columns = [\"Id\", \"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "following columns have greater than 90% data missing or NULL \n",
      " Alley           0.937671\n",
      "PoolQC          0.995205\n",
      "MiscFeature     0.963014\n",
      "LowQualFinSF    0.982192\n",
      "BsmtHalfBath    0.943836\n",
      "3SsnPorch       0.983562\n",
      "ScreenPorch     0.920548\n",
      "PoolArea        0.995205\n",
      "MiscVal         0.964384\n",
      "dtype: float64\n",
      "original df shape =  (1460, 79)\n",
      "final df shape =  (1460, 70)\n"
     ]
    }
   ],
   "source": [
    "# find missing data.. remove colums that have > 90% data missing\n",
    "missingData = columnsWithMissingData(X, threshold = 0.9)\n",
    "print(\"following columns have greater than 90% data missing or NULL \\n\",missingData)\n",
    "print(\"original df shape = \", X.shape)\n",
    "X = X.drop(columns = missingData.keys())\n",
    "print(\"final df shape = \", X.shape)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature scaling for numerical features\n",
    "numeric_features = X.select_dtypes(exclude=object) \n",
    "num_features_names = numeric_features.columns\n",
    "\n",
    "# features that need a log transformation\n",
    "log_features_names = [\"LotFrontage\", \"LotArea\", \"1stFlrSF\", \"GrLivArea\", \"OpenPorchSF\"]\n",
    "\n",
    "log_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('logscaler', FunctionTransformer(np.log1p, validate=False)),\n",
    "    ('scaler', RobustScaler())])\n",
    "\n",
    "#numeric features that require a normal transformation\n",
    "numeric_features_names = [x for x in num_features_names if x not in log_features_names]\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', RobustScaler())])\n",
    "\n",
    "transformers=[\n",
    "        ('log', log_pipeline, log_features_names),\n",
    "        ('num', numeric_pipeline, numeric_features_names),  \n",
    "    ]\n",
    "\n",
    "# ensure that result is always a dense matrix\n",
    "ct = ColumnTransformer(transformers=transformers, sparse_threshold = 0)\n",
    "Xt = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers from numeric data\n",
    "Xt, Y, outliers = outlierRemoval_ZScore(Xt, Y, 8, bypass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xt shape:  (1460, 30)\n",
      "X_pca_t shape:  (1460, 30)\n"
     ]
    }
   ],
   "source": [
    "# use PCA to fit and transform the data using a 0.95 variance\n",
    "#pca = PCA(0.99)\n",
    "X_pca_t = Xt\n",
    "print(\"Xt shape: \", Xt.shape)\n",
    "print(\"X_pca_t shape: \", X_pca_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_names = X.select_dtypes(include=object).columns\n",
    "#categorical_features_names = CAT_COLS\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "X_cat_t = cat_pipeline.fit_transform(X[categorical_features_names])\n",
    "\n",
    "# remove corresponding outlier rows from the categorical data\n",
    "X_cat_t2 = np.delete(X_cat_t.todense(), outliers, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated Xt shape:  (1460, 286)\n"
     ]
    }
   ],
   "source": [
    "# concatenate the numerical and one hot encoded categorical data\n",
    "Xt = np.concatenate((X_pca_t, X_cat_t2 ), axis = 1)\n",
    "print(\"concatenated Xt shape: \", Xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   18.1s remaining:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   18.2s remaining:   12.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model xgb cross_val_score took 28.092942714691162 seconds\n",
      "Scores: [14448.54759739 15613.00917701 15384.99277611 12693.11966235\n",
      " 15511.87829088]\n",
      "Mean: 14730.309500749145\n",
      "standard deviation: 1099.831886343229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   27.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   27.7s finished\n"
     ]
    }
   ],
   "source": [
    "# try xgboost\\n\",\n",
    "xgb_model = xgb.XGBRegressor(colsample_bytree=0.8, subsample=0.5,\n",
    "                            learning_rate=0.05, max_depth=5,\n",
    "                              min_child_weight=1.8, n_estimators=500,\n",
    "                               reg_alpha=0.9, reg_lambda=0.9, gamma=0.001, \n",
    "                              silent=1, random_state =7, nthread = -1, refit = True)\n",
    "\n",
    "crossValidateModel(xgb_model, Xt, Y, \"xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ............................... , score=-14622.205, total=   0.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ............................... , score=-16395.725, total=   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  ................................................................\n",
      "[CV] ............................... , score=-16166.830, total=   0.3s\n",
      "[CV]  ................................................................\n",
      "[CV] ............................... , score=-13678.097, total=   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  ................................................................\n",
      "[CV] ............................... , score=-16310.203, total=   0.3s\n",
      "model lightgbm cross_val_score took 1.2451128959655762 seconds\n",
      "Scores: [14622.20450507 16395.72494209 16166.82998958 13678.09667234\n",
      " 16310.20252795]\n",
      "Mean: 15434.611727405258\n",
      "standard deviation: 1092.8762124313746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                                 learning_rate=0.05, n_estimators=720,\n",
    "                                 max_bin = 55, bagging_fraction = 0.8,\n",
    "                                 bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                                 feature_fraction_seed=9, bagging_seed=9,\n",
    "                                 min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "crossValidateModel(model_lgb, Xt, Y, \"lightgbm\", 1) # 1 job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the grid serach results to create the final predictor for the test\n",
    "elastic_net= ElasticNet(alpha = 0.2, l1_ratio = 0.9)\n",
    "elastic_net.fit(Xt,Y)\n",
    "\n",
    "#path to file you will use for predictions\n",
    "test_data_path = '../data/test.csv'\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "X_test = test_data.drop(columns = [\"Id\"])\n",
    "X_test = test_data.drop(columns = missingData.keys())\n",
    "# numerical columns\n",
    "X_num_test = ct.fit_transform(X_test)\n",
    "# PCA on the numerical data\n",
    "X_pca_test = X_num_test\n",
    "# categorical colums that are OHE\n",
    "X_cat_test = cat_pipeline.transform(X_test[categorical_features_names])\n",
    "\n",
    "X_final_test = np.concatenate((X_pca_test, X_cat_test.todense() ), axis = 1)\n",
    "#make predictions which we will submit. \n",
    "y_pred = elastic_net.predict(X_final_test)\n",
    "\n",
    "#The lines below shows how to save predictions in format used for competition scoring\n",
    "output = pd.DataFrame({'Id': test_data.Id,\n",
    "                       'SalePrice': y_pred})\n",
    "output.to_csv('../data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "est=GradientBoostingRegressor(n_estimators=600, max_depth=5, loss='ls',min_samples_split=2,learning_rate=0.1, verbose = 5).fit(Xt, np.log(Y))\n",
    "y_pred = est.predict(X_final_test)\n",
    "\n",
    "#The lines below shows how to save predictions in format used for competition scoring\n",
    "output = pd.DataFrame({'Id': test_data.Id,\n",
    "                       'SalePrice': np.exp(y_pred)})\n",
    "output.to_csv('../data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "\n",
    "adaboost_model = AdaBoostRegressor(base_estimator= elastic_net, random_state=5, n_estimators=1000)\n",
    "adaboost_model.fit(Xt, np.log(Y))\n",
    "y_pred = adaboost_model.predict(X_final_test)\n",
    "\n",
    "#The lines below shows how to save predictions in format used for competition scoring\n",
    "output = pd.DataFrame({'Id': test_data.Id,\n",
    "                       'SalePrice': np.exp(y_pred)})\n",
    "output.to_csv('../data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
