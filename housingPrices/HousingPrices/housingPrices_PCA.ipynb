{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (RandomForestRegressor, IsolationForest)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import (train_test_split, GridSearchCV)\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (StandardScaler, OneHotEncoder, FunctionTransformer, KBinsDiscretizer)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KitchenQual', 'GarageCond', 'GarageQual', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'LotConfig', 'Utilities', 'LandSlope', 'LotShape', 'GarageType', 'BldgType', 'CentralAir', 'MSZoning', 'LandContour', 'PavedDrive']\n"
     ]
    }
   ],
   "source": [
    "CONDITIONS_DICT = {\"NA\": 0, \"NaN\": 0, \"nan\": 0, \"Po\": 2, \"Fa\": 3, \"TA\": 4, \"Gd\":6, \"Ex\": 10}\n",
    "\n",
    "# constants\n",
    "CATEGORY_LABELS = {\"KitchenQual\":       CONDITIONS_DICT,\n",
    "                    \"GarageCond\":       CONDITIONS_DICT,\n",
    "                    \"GarageQual\":       CONDITIONS_DICT,\n",
    "                    \"ExterQual\":        CONDITIONS_DICT,\n",
    "                    \"ExterCond\":        CONDITIONS_DICT,\n",
    "                    \"BsmtQual\":         CONDITIONS_DICT,\n",
    "                    \"BsmtCond\":         CONDITIONS_DICT,\n",
    "                    \"FireplaceQu\" :     CONDITIONS_DICT,\n",
    "                    \"HeatingQC\" :       CONDITIONS_DICT,\n",
    "                    \"LotConfig\":     {\"Inside\": 0, \"Corner\": 6, \"CulDSac\": 10, \"FR2\": 3, \"FR3\":4},\n",
    "                    \"Utilities\":     {\"ELO\": 0, \"NoSeWa\": 1, \"NoSewr\": 2, \"AllPub\": 3},\n",
    "                    \"LandSlope\":     {\"Gtl\": 10, \"Mod\": 4, \"Sev\": 1},\n",
    "                    \"LotShape\":     {\"Reg\": 10, \"IR1\": 5, \"IR2\": 3, \"IR3\": 1},\n",
    "                    \"GarageType\":     {\"NA\": 0, \"nan\": 0, \"Basment\": 4,  \"Detchd\": 1, \"CarPort\": 3, \"BuiltIn\": 5, \"Attchd\": 7, \"2Types\": 12},\n",
    "                    \"BldgType\":     {\"TwnhsI\": 1, \"Twnhs\": 2, \"TwnhsE\": 3, \"Duplex\": 5,  \"2fmCon\": 7, \"1Fam\": 12},\n",
    "                    \"CentralAir\":     {\"N\": 1, \"Y\": 10},\n",
    "                    \"Electrical\":     {\"Mix\": 1, \"FuseP\": 3, \"FuseF\": 5,  \"FuseA\": 7, \"SBrkr\": 12},\n",
    "                    \"MSZoning\":     {\"RL\": 100, \"RM\": 60, \"C (all)\": 20, \"FV\": 30, \"RH\": 30},\n",
    "                    \"LandContour\":     {\"Lvl\": 100, \"Low\": 15, \"Bnk\": 25, \"HLS\": 5},\n",
    "                    \"Fence\":     {\"NA\": 0, \"MnPrv\": 25, \"MnWw\": 15, \"GdWo\": 40, 'GdPrv': 100},\n",
    "                    \"Functional\":     {\"Typ\": 100, \"Min1\": 70, \"Min2\": 50, \"Mod\": 40, \"Maj1\": 25, \"Maj2\": 20, \"Min2\": 10, \"Sev\": 5, \"Sal\": 1},\n",
    "                    \"MiscFeature\":     {\"NA\": 0, \"Shed\": 30, \"Gar2\": 40, \"Othr\": 25, \"TenC\": 100},\n",
    "                    \"PavedDrive\":     {\"Y\": 100, \"P\": 30, \"N\": 0},\n",
    "                    }\n",
    "\n",
    "CAT_COLS_TO_IGNORE = [\"Functional\",\n",
    "                        \"MiscFeature\",\n",
    "                        \"Electrical\",\n",
    "                        \"Fence\",\n",
    "                        \"FireplaceQu\",\n",
    "                        \"HeatingQC\"           \n",
    "                    ]\n",
    "\n",
    "CAT_COLS = [ x for x in CATEGORY_LABELS.keys() if x not in CAT_COLS_TO_IGNORE]\n",
    "print(CAT_COLS)\n",
    "\n",
    "# plot correlations\n",
    "def plotCoorelations(df):\n",
    "    # remove non_numeric features  \n",
    "    corr = df.corr()\n",
    "    corr.style.background_gradient(cmap='coolwarm').set_precision(2)\n",
    "\n",
    "# define a method to use Isolation Forest for outlier detection\n",
    "def outlierRemoval_IsolationForest(X, y, outlierFraction = 0.02):\n",
    "    clf = IsolationForest( behaviour = 'new', contamination = outlierFraction)\n",
    "    preds = clf.fit_predict(X)\n",
    "    outliers = np.where(preds == -1)\n",
    "    return dropOutliers(X, y, outliers)\n",
    "\n",
    "def dropOutliers(X, y, outliers):\n",
    "    print(\"number of outliers = {0}\".format(len(outliers[0])))\n",
    "    # drop outliers\n",
    "    X_clean = np.delete(X, outliers[0], axis = 0)\n",
    "    y_clean = np.delete(y.values, outliers[0])\n",
    "    return X_clean, y_clean, outliers[0] \n",
    "\n",
    "# define a method to use Isolation Forest for outlier detection\n",
    "def outlierRemoval_ZScore(X, y, zValue = 3):\n",
    "    z = np.abs(stats.zscore(X))\n",
    "    outliers = np.where(z > zValue)\n",
    "    return dropOutliers(X, y, outliers)\n",
    "\n",
    "def getTransformedColumnNames(ct):\n",
    "    for item in ct.named_transformers_:\n",
    "       pipeline = ct.named_transformers_[item]\n",
    "       for step in pipeline.named_steps:\n",
    "           t1 = pipeline.named_steps[step]\n",
    "           print(t1.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1314, 79)\n"
     ]
    }
   ],
   "source": [
    "# load housing data\n",
    "iowa_file_path = '../data/train.csv'\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "Y = home_data[\"SalePrice\"]\n",
    "X = home_data.drop(columns = [\"Id\", \"SalePrice\"])\n",
    "\n",
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=1)\n",
    "print(X_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "number of outliers = 22\n",
      "(1294, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.775882037622836"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform feature scaling\n",
    "\n",
    "numeric_features = X_train.select_dtypes(exclude=object) \n",
    "num_features_names = numeric_features.columns\n",
    "\n",
    "# features that need a log transformation\n",
    "log_features_names = [\"LotFrontage\", \"LotArea\", \"1stFlrSF\", \"GrLivArea\", \"OpenPorchSF\"]\n",
    "\n",
    "log_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('logscaler', FunctionTransformer(np.log1p, validate=False)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "#numeric features that require a normal transformation\n",
    "numeric_features_names = [x for x in num_features_names if x not in log_features_names]\n",
    "print(len(numeric_features_names))\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "transformers=[\n",
    "        ('log', log_pipeline, log_features_names),\n",
    "        ('num', numeric_pipeline, numeric_features_names),  \n",
    "    ]\n",
    "\n",
    "# ensure that result is always a dense matrix\n",
    "ct = ColumnTransformer(transformers=transformers, sparse_threshold = 0)\n",
    "Xt = ct.fit_transform(X_train)\n",
    "\n",
    "# perform mean normalization and feature scaling on the data\n",
    "#X_train_t, y_t1 = outlierRemoval_IsolationForest(Xt.copy(), y_train.copy())\n",
    "X_train_t, y_t2, outliers = outlierRemoval_ZScore(Xt.copy(), y_train.copy(), 9)\n",
    "print(X_train_t.shape)\n",
    "np.amax(X_train_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1314, 75)\n",
      "(1294, 100)\n",
      "(1294,)\n"
     ]
    }
   ],
   "source": [
    "# use PCA to fit and transform the data using a 0.95 variance\n",
    "pca = PCA(0.95)\n",
    "X_pca_t = pca.fit_transform(X_train_t)\n",
    "\n",
    "# OHE the categorical features and then remove the outlers\n",
    "#categorical features\n",
    "#categorical_features_names = X_train.select_dtypes(include=object).columns\n",
    "categorical_features_names = CAT_COLS\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "X_cat_t = cat_pipeline.fit_transform(X_train[categorical_features_names])\n",
    "print(X_cat_t.shape)\n",
    "X_cat_t2 = np.delete(X_cat_t.todense(), outliers, axis = 0)\n",
    "X_t3 = np.concatenate((X_pca_t, X_cat_t2 ), axis = 1)\n",
    "print(X_t3.shape)\n",
    "print(y_t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit took 64.28000092506409 seconds\n"
     ]
    }
   ],
   "source": [
    "# use random forest regressor \n",
    "\n",
    "clf = RandomForestRegressor(random_state=1, n_estimators = 500, criterion=\"mae\", n_jobs=-1)\n",
    "\n",
    "# fit the log of the sale price\n",
    "start = time.time()\n",
    "clf.fit(X_t3, np.log1p(y_t2))\n",
    "end = time.time()\n",
    "elapsed_time = end - start\n",
    "print(\"fit took {0} seconds\".format(elapsed_time))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 51)\n",
      "(146, 25)\n"
     ]
    }
   ],
   "source": [
    "X_cat_t3 = cat_pipeline.transform(X_test[categorical_features_names])\n",
    "print(X_cat_t3.shape)\n",
    "\n",
    "# transform the test data\n",
    "Xt = ct.transform(X_test)\n",
    "X_pca_test = pca.transform(Xt)\n",
    "print(X_pca_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE for Random Forest Model: 17,024\n"
     ]
    }
   ],
   "source": [
    "X_test3 = np.concatenate((X_pca_test, X_cat_t3.todense()), axis = 1)\n",
    "y_predict = clf.predict(X_test3)\n",
    "\n",
    "rf_val_mae = mean_absolute_error(y_test, np.expm1(y_predict))\n",
    "print(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
